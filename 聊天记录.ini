3. 公司内部共享文件夹：\\192.168.2.33 查看公司的公共信息(政策程序及规章制度)和您的网络文件夹。
用户名：<英文名>.<姓>
密码：Jj123456


QA 环境

盛尧 2014/11/10 15:57:11
http://memberqa.jje.com:5555


<dependency>
    <groupId>com.oracle</groupId>
    <artifactId>ojdbc14</artifactId>
    <version>10.2.0.5.0</version>
</dependency>


<dependency>
	<groupId>com.sun</groupId>
	<artifactId>tools</artifactId>
	<version>1.5.0</version>
	<scope>system</scope>
	<systemPath>C:/Program Files (x86)/Java/jdk1.6.0_38/lib/tools.jar</systemPath>
</dependency>



http://course.jje.com/


-Dtangosol.coherence.localhost=127.0.0.1 -Dtangosol.coherence.ttl=0 -DXms512m -DXmx1024m -DXX:MaxNewSize=256m -DXX:MaxPermSize=256m jetty:run


13510010008@qq.com


DB
jdbc:oracle:thin:@192.168.5.7:1521:Testqa
memberqa
654321


\\192.168.1.112\jje\CRM组周报\


http://memberqa.jje.com:5555/admin/coupon/rule/index
http://memberqa.jje.com:5555/admin/coupon/rule/addRule
http://memberqa.jje.com:5555/admin/coupon/rule/effective



192.168.5.6
weblogic
weblogic123


secureCRT
memberqa
192.168.5.6
weblogic
weblogic123

bananaqa
192.168.5.138
weblogic / root
123456



日志
/logs/integration_fixbug/



http://mjenkins.jje.com/view/banana/




http://banana.jje.com:5555/



重启weblogic
/home/weblogic/Weblogic/user_projects/domains/InteQA_Domain123
nohup startWebLogic.sh &



<webMemberDto>
	<email>t011</email>
	<pwd>E10ADC3949BA59ABBE56E057F20F883E</pwd>
	<registChannel>Website</registChannel>
</webMemberDto>



url：  vbp/webMember/regist


\\192.168.1.220\imgdir 3\uat\3uat\bp\6066

dataview  datamember1 oggdb
dataview  viewer321 jjedb_standby
bigdata	  bigdata4321   JJEPDB_NEW
dataview  dataview123  NBPDB


堡垒机CRT
weblogic/123456

---------------------------------------大数据----------------------------------------------
svn://svn.jje.com/hadoop

http://116.236.229.44/mobile/auth/login.aspx

172.24.104.9 10 13 14

UAT 192.168.101.2
VSVR-40.200    192.168.100.200     root 123456Aa
VSVR-40.201    192.168.100.201     root 123456Aa
DB01        192.168.101.2 root Huawei@CLOUD8!
DB02        192.168.101.3 root Huawei@CLOUD8!


svn://svn.jje.com/cms/bd.branches
svn://svn.jje.com/dto/bd.branches
svn://svn.jje.com/durian/bd.branches
svn://svn.jje.com/melon/bd.branches

192.168.5.195 199 200 测试环境

create external table T_DBP_PASS_USER_VIEW (rowkey string,member_id string)
ROW FORMAT DELIMITED COLLECTION ITEMS TERMINATED BY '|'
STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
WITH SERDEPROPERTIES("hbase.columns.mapping"="
info:MC_MEMBER_CODE")
TBLPROPERTIES("hbase.table.name"="T_DBP_PASS_USER_VIEW");


transwarp -t -h 172.24.104.13
set ngmr.ppd=false;
SELECT   v.rowkey,get_json_object(v.datajson,'$.productId') as productId,v.useragent as mc_code FROM   t_dbp_pass_user_view v left join TB_REC_COOKIE_MEMBERINFO cookie on v.useragent = cookie.rowkey WHERE
(v.viewurl LIKE '%#0J%' OR   v.viewurl LIKE '%#RE%') AND   get_json_object(v.datajson,'$.productId') is not null AND   substring(v.rowkey,0,4) = '2014' AND   v.useragent NOT RLIKE '^\\d{1,10}$' ORDER BY rowkey;

transwarp -t -h 172.24.104.13
set ngmr.ppd=false;
SELECT
  v.rowkey,get_json_object(v.datajson,'$.productId') as productId,cookie.member_id
FROM
  t_dbp_pass_user_view v join TB_REC_COOKIE_MEMBERINFO cookie on cookie.rowkey = v.utrace
WHERE
  (v.viewurl LIKE '%#0J%'
OR
  v.viewurl LIKE '%#RE%')
AND
  get_json_object(v.datajson,'$.productId') is not null
AND
   substring(v.rowkey,0,4) = '2014'
AND
   v.useragent NOT RLIKE '^\\d{1,10}$'
ORDER BY rowkey;


如何计算大数据推荐产生的订单？

1、pageview中有浏览过推荐系统推荐的线路与酒店（包括网站与EDM渠道）
2、（此条仅针对旅游与酒店）浏览过推荐产品后的30天内，购买过此产品的，计入推荐产生订单
3、（此条仅针对旅游）浏览过推荐产品后的30天内，购买过与此线路相同目的地大区产品的，计入推荐产生订单
4、（此条仅针对酒店）浏览过推荐产品后的30天内，购买过与此酒店相同入住城市产品的，计入推荐产生订单

统计结果
1、区分旅游、酒店板块
2、统计维度包括： 订单数、订单金额、购买人数


http://st tic.jinjiang.com/opt/static/hotel/%%{hotelTopList.results[0].imgUrl}

135545665


http://172.24.8.22:8161/admin/queues.jsp  -- 队列

http://172.24.104.13:60010/master-status

Total:	servers: 4		requestsPerSecond=103, numberOfOnlineRegions=9953


SHOW CREATE TABLE tb_travel_user_profile_tmp_data;  等于desc table name;




googleAPI key :AIzaSyCte6LeclUx0_KOU1q1HwUhNNlAQBLUojM


/etc/init.d/hadoop-hdfs-datanode-hdfs1 status
/etc/init.d/hbase-regionserver-hyperbase1 status

/usr/lib/ngmr/work  spark日志



http://www.boyunjian.com/javasrc/org.apache.servicemix.bundles/org.apache.servicemix.bundles.hbase/0.94_1/_/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java

http://eric-gcm.iteye.com/blog/1807468



sqoop export --connect jdbc:oracle:thin:@172.24.100.22:1522:bieedb02 --username BGDATA --password Aa123456 --table CONTACT_INFO --columns ROWKEY,CELL_PH_NUM,MOBILE_AREA,CRM_LAST_UPD,LAST_UPD,AGE,GENDER,BIRTHDAY,CONSTELLATION,X_ID_NUM,X_ID_TYPE_CD,ZODIAC,MOBILE_TYPE --update-key ROWKEY --update-mode allowinsert --export-dir hdfs:$HDFS --input-fields-terminated-by '\001'


scan 'TB_TRAVEL_USER_PROFILE',{FILTER=>"SingleColumnValueFilter('info', 'TOTAL_CONSUMPTION_NUMBER', =, 'binary:2')", LIMIT=>100}



清除临时文件:{
	cd /usr/lib/ngmr
	rm -r -f logs
	ln -s /dev/shm/logs/ngmr/logs logs
	chown -R yarn:yarn logs
	rm -r -f work
	ln -s /dev/shm/logs/ngmr/work work
	chown -R yarn:yarn work
}



chrome瞬时加密过弱:{
	C:\Program Files (x86)\Google\Chrome\Application\chrome.exe" --cipher-suite-blacklist=0x0088,0x0087,0x0039,0x0038,0x0044,0x0045,0x0066,0x0032,0x0033,0x0016,0x0013
}


内存表:{
	create table newTbale tblproperties('cache'='ram') as select * from originalTable;
}

VOICE GRILS VOL.25:{
	https://item.taobao.com/item.htm?id=526955043842&spm=a310v.4.88.1
}

拍票:{
	http://auctions.search.yahoo.co.jp/search?p=%E3%80%8C%E3%81%94%E6%B3%A8%E6%96%87%E3%81%AF%E3%81%86%E3%81%95%E3%81%8E%E3%81%A7%E3%81%99%E3%81%8B%EF%BC%9F%EF%BC%9F%E3%80%8DRabbit+House+Tea+Party+2016&aq=-1&oq=&x=40&y=20&ei=UTF-8&slider=0&tab_ex=commerce&auccat=
	http://auctions.search.yahoo.co.jp/search?p=%E4%BD%90%E5%80%89%E7%B6%BE%E9%9F%B3&oq=&auccat=0&f=0x2&slider=0&tab_ex=commerce&ei=UTF-8&b=1
}


UAT控制面板地址{
	192.168.101.11:8180
}

aws document{
	https://docs.amazonaws.cn/ElasticMapReduce/latest/DeveloperGuide/emr-hbase.html,
	http://aws.amazon.com/documentation/elastic-mapreduce/,
	http://aws.amazon.com/
}


aws s3distcp{
	 hadoop jar ~/lib/emr-s3distcp-1.0.jar --src s3://bigdata.jinjiang.com/ --dest hdfs:///test-s3copy
}

s3://bigdata.jinjiang.com/test_data/hbase/JJ000_WEBSITE_T_HBP_HOTEL_MAP

amazon hadoop jars{
	/home/hadoop/share/hadoop/common,
}

qa-queues:{
	http://192.168.5.30:8161/admin/queues.jsp
}



svn://svn.jje.com/dbp/trunk
svn://svn.jje.com/dbp/branches/R1720_Transwarp_Old_Version_20160128/common

svn://svn.jje.com/lemon/bd.branches/BD.F002.T
svn://svn.jje.com/hadoop/branches/Doc
svn://svn.jje.com/pear/branches/deploy_config
svn://svn.jje.com/dto/bd.branches/BD.F002.T


unset jars

for f in /home/hadoop/jars/*.jar; do
   jars=${jars}$f,
done

jars=${jars%?}

echo $jars

/home/hadoop/spark/bin/spark-submit \
--class com.jje.bigdata.userProfile.hotel.JoinHotelUserProfileJob \
--num-executors 25 \
--executor-cores 2 \
--executor-memory 12G \
--jars $jars \
--conf spark.shuffle.manager=SORT \
--conf spark.yarn.executor.memoryOverhead=2048 \
/home/hadoop/lexus-1.0-SNAPSHOT.jar 3000 true true


990  top
991  free -m
992  top
993  jps
994  dstat
995  dstat -arni
996  iostat -mx 2
997  dstat -arni
998  ifconfig
999  ethtool eth0
1000  dstat -arni
1001  history

 sudo -u hbase hbase hbck -fixEmptyMetaCells
 sudo -u hbase hbase hbck -fixMeta
 sudo -u hbase hbase hbck -fix